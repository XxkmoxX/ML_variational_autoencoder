{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/venv/cdd/lib/python3.12/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "2025-03-11 15:25:19.215112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-11 15:25:19.232877: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-11 15:25:19.237925: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 15:25:19.251331: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 15:25:20.600926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch                                            # Main deep learning library.\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms            # Handles datasets and transfomations.\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter       # Track training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Variational Autoencoder (VAE) Model \n",
    "\n",
    "### See Conditional VAE that introduces and additional conditioning variable, tipycally labels, allowing for controled generation.\n",
    "\n",
    "'''\n",
    "This class defines the VAE model. It consists of an encoder and a decoder. \n",
    "The encoder compresses the input image into a latent space, and the decoder reconstructs \n",
    "the image from the latent space.\n",
    "'''\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):                             # latent_dim=128: The size of latent representation.\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder                                                   # Features extraction: 4 concolutional layers extract hierarchical image features,\n",
    "        self.encoder = nn.Sequential(                               # each layer halves the images size while increasing feature maps.\n",
    "            nn.Conv2d(3, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(256 * 16 * 16, latent_dim)           # Latent Space Mwean and Variance: fc_mu and fc_logvar predict mean and          \n",
    "        self.fc_logvar = nn.Linear(256 * 16 * 16, latent_dim)       # log-variance for the latent distribution.\n",
    "\n",
    "        # Decoder                                                   # Image reconstruction: Fully connected layer (fc_dec) expands latent vector.\n",
    "        self.fc_dec = nn.Linear(latent_dim, 256 * 16 * 16)          # Tranpose convolutions upsample back to 256x256 image.\n",
    "        self.decoder = nn.Sequential(                               # Final layer uses Sigmoid() to constrain pixel values to [0, 1].\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):                           # Reparametrization trick, allows backpropagation the through the \n",
    "        std = torch.exp(0.5 * logvar)                               # stocastic sampling process. Converts mean and log-variance into a latent vactor.\n",
    "        eps = torch.randn_like(std)                                 # Allows backpropagation through a stochastic operation.\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):                                           # Forward pass of the VAE. It encodes the input, samples from latent space, and \n",
    "        x = self.encoder(x).view(x.size(0), -1)                     # decodes the sample back to the image space. 1) Encodes image --> latent vector(mu, logvar).\n",
    "        mu, logvar = self.fc_mu(x), self.fc_logvar(x)               # 2) Samples z using reparametrization trick. 3) Decodes z baxk to an image.\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x = self.fc_dec(z).view(x.size(0), 256, 16, 16)\n",
    "        x = self.decoder(x)\n",
    "        return x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "'''\n",
    "This function trains the VAE. It initializes the model, optimizer, and TensorBoard writer. \n",
    "It then iterates over the dataset for a specified number of epochs, computes the loss, performs \n",
    "backpropagation, and updates the model parameters. The loss is logged to TensorBoard, \n",
    "and the trained model is saved.\n",
    "'''\n",
    "\n",
    "def train_vae(epochs=10, batch_size=32, latent_dim=128):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")           # Uses GPU if avalaible.\n",
    "    dataloader = get_dataloader(batch_size)                                         # Load dataset using DataLoader.\n",
    "    vae = VAE(latent_dim).to(device)                                                # Initializes model and Adam optimizer.\n",
    "    optimizer = optim.Adam(vae.parameters(), lr=1e-4)                               # Creates TensorBoard logger.\n",
    "    writer = SummaryWriter(\"runs/vae_experiment\")                                   \n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, _ in dataloader:\n",
    "            images = images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = vae(images)\n",
    "            loss = vae_loss(x_recon, images, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)                             # Log loss and save model. Save loss TensorBoard and save trained model for later use.\n",
    "        writer.add_scalar('Loss/train', avg_loss, epoch)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    writer.close()\n",
    "    torch.save(vae.state_dict(), \"vae_256x256.pth\")\n",
    "    return vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and Visualize Samples\n",
    "\n",
    "'''\n",
    "This function generates and visualizes images from the trained VAE. \n",
    "It samples random latent vectors, decodes them into images, and \n",
    "displays the images using Matplotlib.\n",
    "'''\n",
    "\n",
    "def generate_images(vae, num_images=5, latent_dim=128):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    vae.to(device)\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, latent_dim).to(device)                                  # Samples random latent vectors (z).\n",
    "        generated_images = vae.decoder(vae.fc_dec(z).view(num_images, 256, 16, 16))         # Uses decoder to generate images from z.\n",
    "    \n",
    "    generated_images = generated_images.cpu().numpy().transpose(0, 2, 3, 1)                 # Converts tensor tu NumPy forma for visualization.\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))                               \n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(generated_images[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Training Example\n",
    "# vae = train_vae(epochs=10)\n",
    "# generate_images(vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VAE jax/flax/neural network implementation\n",
    "\n",
    "import jax                                  # JAX and JAX NumPy: used for GPU/TPU-accelerated numerical computations.\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn                     # Provides neural network layers (nn.Module)\n",
    "from flax import nnx   #### averiguar que es el modulo nnx\n",
    "import optax                                # Implements optimization algorithms (Adam optimizer)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.data import Dataset\n",
    "from jax.scipy.stats import norm\n",
    "import jax.devices\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Ensure JAX uses GPU/TPU\n",
    "jax.config.update(\"jax_platform_name\", \"gpu\")           # Use \"tpu\" for TPU support\n",
    "\n",
    "### Define Encoder\n",
    "class Encoder(nn.Module):\n",
    "    latent_dim: int\n",
    "\n",
    "    @nn.compact                                                         # Convolutional layers extract images features, reducing spatial dimensions.\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(32, (4, 4), strides=(2, 2), padding='SAME')(x)      # Fully connected layers transform the features into two vectors:\n",
    "        x = nn.relu(x)                                                  # mean: center of the latent distributio, logvar: spread of the latent space\n",
    "        x = nn.Conv(64, (4, 4), strides=(2, 2), padding='SAME')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        x = nn.Dense(128)(x)\n",
    "        x = nn.relu(x)\n",
    "        mean = nn.Dense(self.latent_dim)(x)\n",
    "        logvar = nn.Dense(self.latent_dim)(x)\n",
    "        return mean, logvar\n",
    "\n",
    "### Reparametrization trick                             # Converts mean and logvar into a sample from latent space\n",
    "def reparameterize(rng, mean, logvar):                  # eps is a random noise from a normal distribution                                \n",
    "    std = jnp.exp(0.5 * logvar)                         # ensures gradients can pass through this sampling step\n",
    "    eps = jax.random.normal(rng, std.shape)\n",
    "    return mean + eps *std\n",
    "\n",
    "### Define Decoder\n",
    "class Decoder(nn.Module):                               # Converts the latent vector (z) ---> reconstructed image\n",
    "                                                        # Uses transposed convolutions (unsampling) to restore the spatial resolution\n",
    "    @nn.compact                                         # Uses sigmoid() activation to output pixed values\n",
    "    def __call__(self, z):\n",
    "        x = nn.Dense(128)(z)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(64 * 64 * 64)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = x.reshape((-1, 64, 64, 64))\n",
    "        x = nn.ConvTranspose(64, (4, 4), strides=(2, 2), padding='SAME')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.ConvTranspose(32, (4, 4), strides=(2, 2), padding='SAME')(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.ConvTranspose(3, (4, 4), strides=(2, 2), padding='SAME')(x)\n",
    "        return nn.sigmoid(x)  # Normalize output\n",
    "    \n",
    "### Define VAE                                          # Combines encoder and decoder\n",
    "class VAE(nn.Module):                                   # Takes input images (x), encodes it, samples z, and reconstructs the image\n",
    "    latent_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = Encoder(self.latent_dim)\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def __call__(self, x, rng):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = reparameterize(rng, mean, logvar)\n",
    "        recon_x = self.decoder(z)\n",
    "        return recon_x, mean, logvar\n",
    "    \n",
    "# Loss Function                                         # Recon_loss: measures how different the generated image is from the original\n",
    "def vae_loss(model, params, batch, rng):                # KL divergence: enocurages z to follow a standard normal distribution\n",
    "    recon_x, mean, logvar = model.apply(params, batch, rng)\n",
    "    recon_loss = jnp.mean((batch - recon_x) ** 2)\n",
    "    kl_loss = -0.5 * jnp.mean(1 + logvar - mean**2 - jnp.exp(logvar))\n",
    "    return recon_loss + kl_loss\n",
    "\n",
    "# Optimizer                                             # Uses the Adam optimizer with a learning rate of 0.001\n",
    "optimizer = optax.adam(1e-3)            \n",
    "\n",
    "# Training Step                                         # Computes gradients using jax.value_and_grad(). Ensures runs on GPU/TPU with jax.jit\n",
    "@jax.jit                                                # Updates model parameters using apply_gradients()\n",
    "def train_step(state, batch, rng):                      # jax.jit accelerates execution by compiling the function\n",
    "    loss, grads = jax.value_and_grad(vae_loss)(state.params, batch, rng)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "# Load and Preprocess Personal Images (NumPy Format)            # Uses batching and prefetching for efficeint training\n",
    "def load_personal_dataset(image_folder, batch_size=32):\n",
    "    image_paths = glob(os.path.join(image_folder, \"*.npy\"))     \n",
    "    \n",
    "    def process_image(image_path):\n",
    "        image = np.load(image_path)\n",
    "        image = image.astype(np.float32) / 255.0                # Normalize pixel values to [0,1]\n",
    "        return image\n",
    "    \n",
    "    images = [process_image(path) for path in image_paths]\n",
    "    ds = Dataset.from_tensor_slices(np.array(images))\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)   # Optimizing dataset loading with TensorFlow's AUTOTUNE.\n",
    "    return ds\n",
    "\n",
    "# Training Loop (Optimized for GPU/TPU)                                 # Initializes model parameters\n",
    "def train_vae(model, dataset, epochs=10):                               # Iterates over epochs and dataset\n",
    "    rng = jax.random.PRNGKey(0)                                         # Updates model weights using train_step\n",
    "    state = train_state.TrainState.create(apply_fn=model.apply, params=model.init(rng, jnp.ones([1, 256, 256, 3])), tx=optimizer)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in dataset:\n",
    "            rng, sub_rng = jax.random.split(rng)\n",
    "            state, loss = train_step(state, batch, sub_rng)\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    return state\n",
    "\n",
    "# Visualizing Reconstructions                                           # Visualizes original vs reconstructed images\n",
    "def visualize_reconstructions(model, state, dataset):                   # Plots original images on top row, reconstructions in bottom row\n",
    "    rng = jax.random.PRNGKey(1)\n",
    "    for batch in dataset.take(1):\n",
    "        batch = np.array(batch)\n",
    "        recon_x, _, _ = model.apply(state.params, batch, rng)\n",
    "        fig, axes = plt.subplots(2, len(batch), figsize=(15, 5))\n",
    "        for i in range(len(batch)):\n",
    "            axes[0, i].imshow(batch[i])\n",
    "            axes[0, i].axis('off')\n",
    "            axes[1, i].imshow(recon_x[i])\n",
    "            axes[1, i].axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Example Usage\n",
    "vae = VAE(latent_dim=128)\n",
    "dataset = load_personal_dataset(\"path/to/your/numpy/images\")\n",
    "trained_vae = train_vae(vae, dataset)\n",
    "visualize_reconstructions(vae, trained_vae, dataset)\n",
    "\n",
    "\n",
    "#### Falta hiperparameter tuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    latent_dim: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.encoder = nn.Sequential([\n",
    "            nn.Conv(32, (4, 4), strides=2), nn.relu,\n",
    "            nn.Conv(64, (4, 4), strides=2), nn.relu,\n",
    "            nn.Conv(128, (4, 4), strides=2), nn.relu,\n",
    "            nn.Conv(256, (4, 4), strides=2), nn.relu,\n",
    "        ])\n",
    "        self.fc_mu = nn.Dense(self.latent_dim)\n",
    "        self.fc_logvar = nn.Dense(self.latent_dim)\n",
    "        self.fc_dec = nn.Dense(256 * 16 * 16)\n",
    "        self.decoder = nn.Sequential([\n",
    "            nn.ConvTranspose(128, (4, 4), strides=2), nn.relu,\n",
    "            nn.ConvTranspose(64, (4, 4), strides=2), nn.relu,\n",
    "            nn.ConvTranspose(32, (4, 4), strides=2), nn.relu,\n",
    "            nn.ConvTranspose(3, (4, 4), strides=2), nn.sigmoid,\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.reshape((x.shape[0], -1))\n",
    "        mu, logvar = self.fc_mu(x), self.fc_logvar(x)\n",
    "        std = jnp.exp(0.5 * logvar)\n",
    "        eps = jax.random.normal(jax.random.PRNGKey(0), std.shape)\n",
    "        z = mu + eps * std\n",
    "        x = self.fc_dec(z).reshape((-1, 256, 16, 16))\n",
    "        return self.decoder(x), mu, logvar\n",
    "\n",
    "\n",
    "\n",
    "### TensorFlow (Keras) implementation\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Conv2D(32, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Conv2D(64, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Conv2D(128, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Conv2D(256, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Flatten()\n",
    "        ])\n",
    "        self.fc_mu = layers.Dense(latent_dim)\n",
    "        self.fc_logvar = layers.Dense(latent_dim)\n",
    "        self.fc_dec = layers.Dense(256 * 16 * 16)\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(128, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Conv2DTranspose(64, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Conv2DTranspose(32, (4, 4), strides=2, activation='relu'),\n",
    "            layers.Conv2DTranspose(3, (4, 4), strides=2, activation='sigmoid'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu, logvar = self.fc_mu(x), self.fc_logvar(x)\n",
    "        std = tf.exp(0.5 * logvar)\n",
    "        eps = tf.random.normal(std.shape)\n",
    "        z = mu + eps * std\n",
    "        x = tf.reshape(self.fc_dec(z), (-1, 256, 16, 16))\n",
    "        return self.decoder(x), mu, logvar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cdd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
